#!/usr/bin/env python3
"""
React Interactive Editor - Rewritten Version
Based on intelligent semantic positioning, not dependent on page numbering system
"""

import json
import re
import subprocess
import os
import webbrowser
import openai
from difflib import unified_diff
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure OpenAI client
client = openai.OpenAI(
    api_key=os.getenv("OPENAI_API_KEY"),
    base_url=os.getenv("OPENAI_API_BASE")
)

# Import prompts
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from prompts.react_editor_prompts import (
    DOCUMENT_STRUCTURE_ANALYSIS_PROMPT,
    CODE_LOCATION_PROMPT,
    CODE_MODIFICATION_PROMPT,
    REACT_DECISION_PROMPT,
    create_content_insertion_prompt,
    LATEX_EXPERT_SYSTEM_PROMPT,
    USER_CONFIRMATION_PROMPTS,
    REFERENCE_SEARCH_ENHANCEMENT
)

class ReactInteractiveEditor:
    """
    Intelligent LaTeX editor using ReAct mode for interactive modifications
    Based on document semantic understanding rather than page numbering for positioning
    """
    
    def __init__(self, tex_file_path, source_content=None, workflow_state=None):
        """
        Initialize editor
        
        Args:
            tex_file_path: LaTeX file path
            source_content: Original PDF parsing content (optional, for content expansion)
            workflow_state: Workflow state manager, for accessing intermediate products
        """
        self.tex_file_path = tex_file_path
        self.source_content = source_content
        self.workflow_state = workflow_state
        self.conversation_history = []
        
        # Initialize reference retrieval agent (if workflow state is available)
        self.reference_agent = None
        if workflow_state and workflow_state.is_ready_for_reference_search():
            try:
                # Fix import path - use modules.reference_agent path
                from modules.reference_agent.reference_agent import ReferenceAgent
                self.reference_agent = ReferenceAgent()
                print("   âœ… Reference search agent initialized")
            except ImportError as e:
                try:
                    # Backup import path
                    import sys
                    import os
                    sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
                    from modules.reference_agent.reference_agent import ReferenceAgent
                    self.reference_agent = ReferenceAgent()
                    print("   âœ… Reference search agent initialized (backup path)")
                except Exception as e2:
                    print(f"   âš ï¸ Reference search agent initialization failed: {e2}")
                    self.reference_agent = None
            except Exception as e:
                print(f"   âš ï¸ Reference search agent initialization failed: {e}")
                self.reference_agent = None
        
        # Read document content
        with open(tex_file_path, 'r', encoding='utf-8') as f:
            self.document_content = f.read()
        
        # Generate document structure map
        print("   Generating document structure map...")
        self.document_map = self._build_document_map()
        
        print(f"âœ“ Document loaded and preprocessed: {self.tex_file_path}")
        print(f"  Document size: {len(self.document_content)} characters")
        if source_content:
            print(f"  Original PDF content provided, content expansion feature enabled")
        print()
    
    def _build_document_map(self):
        """
        Build structured map of document to help LLM understand document structure
        
        Returns:
            dict: Document map containing slides list, or None if generation fails
        """
        try:
            system_prompt = DOCUMENT_STRUCTURE_ANALYSIS_PROMPT
            
            prompt = f"Please analyze the following LaTeX document and generate a structured map:\n```latex\n{self.document_content}\n```"
            
            result_json = self._call_llm([{"role": "user", "content": prompt}], system_prompt, json_mode=True)
            
            if result_json and "slides" in result_json:
                print(f"   âœ“ Document map generated: {result_json['total_slides']} slides")
                return result_json
            else:
                print("   âš ï¸ Document map generation failed, will use backup positioning method")
                return None
                
        except Exception as e:
            print(f"   âŒ Document map generation error: {e}")
            return None
    
    def _call_llm(self, messages, system_prompt, temperature=0.1, json_mode=False):
        """
        General LLM calling function
        
        Args:
            messages: Message list
            system_prompt: System prompt
            temperature: Temperature parameter
            json_mode: Whether to use JSON mode
            
        Returns:
            dict|str: LLM response result
        """
        try:
            full_messages = [{"role": "system", "content": system_prompt}] + messages
            response_format = {"type": "json_object"} if json_mode else {"type": "text"}
            
            response = client.chat.completions.create(
                model=os.getenv("OPENAI_MODEL", "gpt-4o"),
                messages=full_messages,
                temperature=temperature,
                response_format=response_format
            )
            content = response.choices[0].message.content
            return json.loads(content) if json_mode else content
        except Exception as e:
            print(f"âŒ LLM call failed: {e}")
            return None
    
    def locate_code_snippet(self, description):
        """
        Intelligently locate code snippets, supports multi-target positioning
        
        Args:
            description: User description
            
        Returns:
            dict: {
                "snippets": [{"slide_number": int, "code": str, "description": str}],
                "analysis": "Analysis result"
            }
        """
        print(f"ReAct Agent [Locating]... {description}")
        
        system_prompt = CODE_LOCATION_PROMPT
        
        # Build complete context including document map
        context_parts = []
        
        if self.document_map:
            map_summary = f"Document Map ({self.document_map['total_slides']} slides total):\n"
            for slide in self.document_map['slides']:
                map_summary += f"Page {slide['slide_number']}: {slide['type']} - {slide.get('title', 'N/A')}"
                if slide.get('section'):
                    map_summary += f" (Section: {slide['section']})"
                if slide.get('has_image'):
                    map_summary += f" [Images: {', '.join(slide.get('image_files', []))}]"
                if slide.get('has_table'):
                    map_summary += " [Contains Table]"
                map_summary += f"\n  Summary: {slide.get('content_summary', 'None')}\n"
            context_parts.append(map_summary)
        else:
            context_parts.append("âš ï¸ Document map unavailable, will analyze based on source code directly")
        
        context_parts.append(f"LaTeX Source Code:\n```latex\n{self.document_content}\n```")
        full_context = "\n\n".join(context_parts)
        
        prompt = f"{full_context}\n\nUser Request: {description}"
        
        result_json = self._call_llm([{"role": "user", "content": prompt}], system_prompt, json_mode=True)
        
        if result_json and result_json.get("snippets"):
            snippets = result_json.get("snippets", [])
            analysis = result_json.get("analysis", "")
            
            print(f"   âœ“ Found {len(snippets)} code snippets")
            if analysis:
                print(f"   ğŸ“‹ Analysis: {analysis}")
            
            for i, snippet_info in enumerate(snippets, 1):
                slide_num = snippet_info.get("slide_number", "Unknown")
                desc = snippet_info.get("description", "")
                code = snippet_info.get("code", "")
                print(f"   {i}. Page {slide_num}: {desc} ({len(code)} characters)")
            
            return result_json
        else:
            print("   âŒ Failed to locate relevant code")
            return {"snippets": [], "analysis": "No matching code snippets found"}
    
    def generate_modified_code(self, original_snippet, instruction, full_document_context):
        """
        Generate modified code according to instructions
        
        Args:
            original_snippet: Original code snippet
            instruction: Modification instruction
            full_document_context: Complete document context
            
        Returns:
            str: Modified code, or None if failed
        """
        print(f"ReAct Agent [Modifying]... {instruction}")
        
        system_prompt = CODE_MODIFICATION_PROMPT
        
        # Build complete context including original PDF content
        context_parts = [f"Complete LaTeX document content:\n```latex\n{full_document_context}\n```"]
        
        if self.source_content:
            context_parts.append(f"Original PDF parsing content (for enhancement features):\n```json\n{json.dumps(self.source_content, ensure_ascii=False, indent=2)}\n```")
        
        full_context = "\n\n".join(context_parts)
        
        prompt = f"{full_context}\n\nCode snippet to modify:\n```latex\n{original_snippet}\n```\n\nPlease modify it according to the following instruction:\n{instruction}"
        
        result_json = self._call_llm([{"role": "user", "content": prompt}], system_prompt, json_mode=True)
        
        if not result_json:
            print("âŒ LLM failed to generate valid response")
            return None
            
        modified_code = result_json.get("modified_code")
        
        # Ensure return type is string
        if isinstance(modified_code, list):
            print("âš ï¸ Detected LLM returned list, attempting to convert to string")
            modified_code = '\n'.join(str(item) for item in modified_code)
        elif not isinstance(modified_code, str):
            print(f"âŒ LLM returned invalid type: {type(modified_code)}")
            return None
            
        # Add safety check: prevent LLM from returning entire document
        original_length = len(original_snippet)
        modified_length = len(modified_code)
        
        # If modified code length exceeds 3x original code, may be abnormal
        if modified_length > original_length * 3:
            print(f"âš ï¸ Warning: Modified code length abnormal ({modified_length} vs {original_length})")
            print("This may indicate LLM returned excessive code.")
            
            # Check if contains document header identifiers
            if "\\documentclass" in modified_code and "\\begin{document}" in modified_code:
                print("âŒ Detected LLM incorrectly returned complete document, rejecting this modification")
                return None
        
        return modified_code
    
    def _find_and_replace_frame(self, original_snippet, modified_snippet):
        """
        åœ¨æ–‡æ¡£ä¸­æŸ¥æ‰¾å¹¶æ›¿æ¢ä»£ç ç‰‡æ®µï¼ˆä¸ä¾èµ–é¡µç æ ‡è®°ï¼‰
        
        Args:
            original_snippet: åŸå§‹ä»£ç ç‰‡æ®µ
            modified_snippet: ä¿®æ”¹åçš„ä»£ç ç‰‡æ®µ
            
        Returns:
            tuple: (success: bool, updated_snippet: str)
        """
        try:
            # ç›´æ¥åœ¨æ–‡æ¡£ä¸­æŸ¥æ‰¾åŸå§‹ç‰‡æ®µ
            if original_snippet in self.document_content:
                # æ‰§è¡Œæ›¿æ¢
                old_length = len(self.document_content)
                self.document_content = self.document_content.replace(original_snippet, modified_snippet, 1)
                new_length = len(self.document_content)
                
                if old_length != new_length or original_snippet != modified_snippet:
                    print(f"âœ“ ä¿®æ”¹å·²æˆåŠŸåº”ç”¨åˆ°å†…å­˜ä¸­çš„æ–‡æ¡£")
                    print(f"   æ–‡æ¡£é•¿åº¦å˜åŒ–: {old_length} -> {new_length} ({new_length - old_length:+d})")
                    
                    # å¦‚æœæ–‡æ¡£ç»“æ„å‘ç”Ÿæ˜¾è‘—å˜åŒ–ï¼Œé‡æ–°ç”Ÿæˆåœ°å›¾
                    if abs(new_length - old_length) > 50:  # é˜ˆå€¼å¯è°ƒæ•´
                        print("ğŸ”„ æ£€æµ‹åˆ°æ–‡æ¡£ç»“æ„å˜åŒ–ï¼Œé‡æ–°ç”Ÿæˆæ–‡æ¡£åœ°å›¾...")
                        self.document_map = self._build_document_map()
                    
                    return True, modified_snippet
                else:
                    print("âœ“ ä»£ç å†…å®¹æ— å˜åŒ–ï¼Œè·³è¿‡æ›¿æ¢ã€‚")
                    return True, modified_snippet
            else:
                print("âŒ åœ¨æ–‡æ¡£ä¸­æœªæ‰¾åˆ°åŸå§‹ä»£ç ç‰‡æ®µ")
                print("ğŸ’¡ è¿™å¯èƒ½æ˜¯ç”±äºæ–‡æ¡£åœ¨ä¹‹å‰çš„ä¿®æ”¹ä¸­å·²ç»æ”¹å˜")
                return False, original_snippet
                
        except Exception as e:
            print(f"âŒ æ›¿æ¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False, original_snippet
    
    def show_diff_and_get_confirmation(self, original_snippet, modified_snippet):
        """
        æ˜¾ç¤ºdiffå¹¶è¯·æ±‚ç”¨æˆ·ç¡®è®¤
        
        Args:
            original_snippet: åŸå§‹ä»£ç 
            modified_snippet: ä¿®æ”¹åä»£ç 
            
        Returns:
            bool: ç”¨æˆ·æ˜¯å¦ç¡®è®¤
        """
        if not isinstance(original_snippet, str) or not isinstance(modified_snippet, str):
            print(f"âŒ å‚æ•°ç±»å‹é”™è¯¯")
            return False

        diff = unified_diff(
            original_snippet.splitlines(keepends=True),
            modified_snippet.splitlines(keepends=True),
            fromfile='original', tofile='modified',
        )
        
        print("\n--- å»ºè®®çš„ä¿®æ”¹ ---")
        diff_str = "".join(diff)
        if not diff_str.strip():
            print("ğŸ¤” æœªæ£€æµ‹åˆ°ä»£ç å˜åŒ–ã€‚")
            return False

        for line in diff_str.splitlines():
            if line.startswith('---') or line.startswith('+++'):
                continue
            elif line.startswith('-'):
                print(f"\033[91m{line}\033[0m")  # çº¢è‰²
            elif line.startswith('+'):
                print(f"\033[92m{line}\033[0m")  # ç»¿è‰²  
            elif line.startswith('@@'):
                print(f"\033[94m{line}\033[0m")  # è“è‰²
            else:
                print(line)
        
        print("--------------------")
        
        while True:
            response = input("æ‚¨æ¥å—è¿™ä¸ªä¿®æ”¹å—ï¼Ÿ(y/n/c) [y]: ").strip().lower()
            if response in ['', 'y', 'yes']:
                return True
            elif response in ['n', 'no']:
                return False
            elif response in ['c', 'cancel']:
                return False
            else:
                print("è¯·è¾“å…¥ y(æ˜¯)ã€n(å¦) æˆ– c(å–æ¶ˆ)")

    def decide_next_action(self):
        """
        åŸºäºå¯¹è¯å†å²å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
        
        Returns:
            dict: å†³ç­–ç»“æœ
        """
        print("ReAct Agent [æ€è€ƒä¸­]... æ­£åœ¨åˆ†ææ‚¨çš„éœ€æ±‚ã€‚")
        
        system_prompt = REACT_DECISION_PROMPT
        decision_json = self._call_llm(self.conversation_history, system_prompt, json_mode=True)
        return decision_json

    def _compile_to_pdf(self):
        """
        ç¼–è¯‘LaTeXæ–‡ä»¶ç”ŸæˆPDF
        
        Returns:
            str: PDFæ–‡ä»¶è·¯å¾„ï¼Œæˆ–Noneï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        tex_path = self.tex_file_path
        output_dir = os.path.dirname(tex_path)
        base_name = os.path.basename(tex_path)
        
        # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆpaper-to-beamerç›®å½•ï¼‰
        project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))
        
        # ä½¿ç”¨ç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„ï¼Œè¿™æ›´å¥å£®
        relative_tex_path = os.path.relpath(tex_path, project_root)
        relative_output_dir = os.path.relpath(output_dir, project_root)
        
        print("\n--- æ­£åœ¨ç¼–è¯‘PDFï¼Œè¯·ç¨å€™ ---")
        print(f"   å·¥ä½œç›®å½•: {project_root}")
        print(f"   ç¼–è¯‘æ–‡ä»¶: {relative_tex_path}")
        print(f"   è¾“å‡ºç›®å½•: {relative_output_dir}")
        
        for i in range(2):
            print(f"ç¼–è¯‘ç¬¬ {i+1}/2 æ¬¡...")
            try:
                # åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œï¼Œå¹¶ä½¿ç”¨ç›¸å¯¹è·¯å¾„
                process = subprocess.run(
                    ["xelatex", "-shell-escape", "-interaction=nonstopmode", f"-output-directory={relative_output_dir}", relative_tex_path],
                    cwd=project_root, capture_output=True, text=True, check=True
                )
                print(f"âœ“ ç¬¬ {i+1} æ¬¡ç¼–è¯‘æˆåŠŸ")
            except subprocess.CalledProcessError as e:
                print(f"âŒ ç¬¬ {i+1} æ¬¡ç¼–è¯‘å¤±è´¥")
                print("é”™è¯¯ä¿¡æ¯:")
                print(e.stdout[-1000:] if e.stdout else "æ— æ ‡å‡†è¾“å‡º")
                print(e.stderr[-1000:] if e.stderr else "æ— é”™è¯¯è¾“å‡º")
                return None
            except FileNotFoundError:
                print("âŒ æ‰¾ä¸åˆ° xelatex å‘½ä»¤ã€‚è¯·ç¡®ä¿å·²å®‰è£… LaTeX ç¯å¢ƒã€‚")
                return None
        
        pdf_path = os.path.join(output_dir, os.path.splitext(base_name)[0] + '.pdf')
        if os.path.exists(pdf_path):
            print(f"âœ… ç¼–è¯‘æˆåŠŸï¼PDFå·²ç”Ÿæˆ: {pdf_path}")
            return pdf_path
        else:
            print("âŒ ç¼–è¯‘å®Œæˆä½†æœªæ‰¾åˆ°PDFæ–‡ä»¶ã€‚")
            return None

    def run_interactive_session(self):
        """
        è¿è¡Œäº¤äº’å¼ç¼–è¾‘ä¼šè¯ - æ–°ç‰ˆæœ¬å®ç°
        """
        print("=== Interactive LaTeX Editor (ReAct Mode) ===")
        print("Describe your modifications in natural language. You can:")
        print("â€¢ Modify existing slide content")
        if self.source_content:
            print("â€¢ Add new slides or expand content based on the original paper")
        print("â€¢ Type 'save' to save changes and exit")
        print("â€¢ Type 'quit' to exit without saving")
        print("ğŸ”„ After each modification, PDF will be automatically compiled for preview")
        print()
        
        while True:
            try:
                user_input = input("ğŸ”§ Enter your request > ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                    print("Goodbye!")
                    break
                elif user_input.lower() in ['save', 'ä¿å­˜', 's']:
                    print("ğŸ”„ Saving changes...")
                    self._save_document_if_requested()
                    break
                elif not user_input: 
                    continue

                self.conversation_history.append({"role": "user", "content": user_input})
                
                decision = self.decide_next_action()
                
                if not decision or "action" not in decision:
                    print("âŒ Cannot understand your request, please try a different way.")
                    self.conversation_history.append({"role": "assistant", "content": "Sorry, I cannot understand your request."})
                    continue

                if decision["action"] == "clarify":
                    question = decision.get("question", "Please provide more details.")
                    print(f"Agent: {question}")
                    self.conversation_history.append({"role": "assistant", "content": question})
                    continue
                
                if decision["action"] == "plan":
                    plan = decision.get("plan")
                    if not plan:
                        print("âŒ Plan generation failed.")
                        continue
                    
                    print("\nâœ“ Execution plan generated:")
                    for step in plan:
                        print(f"  - Step {step['step']} ({step['action']}): {step['description']}")
                    print()

                    # æ‰§è¡Œè®¡åˆ’
                    print("ğŸ”„ Executing plan...")
                    self._execute_plan(plan)
                    print("âœ… Plan execution completed")
                    
                    # è‡ªåŠ¨ç¼–è¯‘PDFè®©ç”¨æˆ·çœ‹åˆ°æ•ˆæœ
                    print("ğŸ”„ Compiling PDF to show changes...")
                    pdf_path = self._compile_to_pdf()
                    if pdf_path:
                        print(f"âœ… PDF updated: {pdf_path}")
                        print("ğŸ“„ You can now review the changes in the PDF")
                    else:
                        print("âš ï¸ PDF compilation failed, but changes are saved in memory")
                    
                    # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­ä¿®æ”¹
                    print("\n" + "="*60)
                    print("ğŸ¯ Changes applied! You can:")
                    print("   â€¢ Enter new modification requests")
                    print("   â€¢ Type 'save' to save changes and exit")
                    print("   â€¢ Type 'quit' to exit without saving")
                    print("="*60)
                    
                    # é‡ç½®å¯¹è¯å†å²ï¼Œå¼€å§‹æ–°çš„ä»»åŠ¡
                    self.conversation_history = []

            except KeyboardInterrupt:
                print("\nGoodbye!")
                break
            except Exception as e:
                print(f"âŒ Critical error occurred: {e}")
                import traceback
                traceback.print_exc()
                print("ğŸ”§ Please check the error details above and try again.")

    def _execute_plan(self, plan):
        """
        æ‰§è¡Œè®¡åˆ’ - æ–°ç‰ˆæœ¬å®ç°
        
        Args:
            plan: æ‰§è¡Œè®¡åˆ’åˆ—è¡¨
        """
        locate_results = None
        
        for step in plan:
            print(f"--- æ­£åœ¨æ‰§è¡Œæ­¥éª¤ {step['step']}/{len(plan)} ---")
            
            if step['action'] == 'locate':
                # ä½¿ç”¨æ–°çš„æ™ºèƒ½å®šä½ç³»ç»Ÿ
                locate_results = self.locate_code_snippet(step['description'])
                if not locate_results or not locate_results.get("snippets"):
                    print("âŒ å®šä½å¤±è´¥ï¼Œä¸­æ­¢è®¡åˆ’ã€‚")
                    break
                print("âœ“ å®šä½æˆåŠŸï¼")
                
            elif step['action'] == 'modify':
                if locate_results and locate_results.get("snippets"):
                    # åŸºäºå®šä½ç»“æœè¿›è¡Œä¿®æ”¹ - ä¸€æ¬¡å¤„ç†ä¸€ä¸ªç‰‡æ®µ
                    self._execute_modifications(locate_results, step['description'])
                else:
                    print("âŒ ä¿®æ”¹å¤±è´¥ï¼Œå‰ä¸€æ­¥çš„å®šä½æœªæˆåŠŸã€‚")
                    break
                    
            elif step['action'] == 'insert':
                if locate_results and locate_results.get("snippets"):
                    # æ‰§è¡Œæ’å…¥æ“ä½œ
                    self._execute_insert(locate_results, step['description'])
                else:
                    print("âŒ æ’å…¥å¤±è´¥ï¼Œå‰ä¸€æ­¥çš„å®šä½æœªæˆåŠŸã€‚")
                    break
                    
            elif step['action'] == 'delete':
                if locate_results and locate_results.get("snippets"):
                    # æ‰§è¡Œåˆ é™¤æ“ä½œ
                    self._execute_delete(locate_results, step['description'])
                else:
                    print("âŒ åˆ é™¤å¤±è´¥ï¼Œå‰ä¸€æ­¥çš„å®šä½æœªæˆåŠŸã€‚")
                    break
                    
            elif step['action'] == 'reference_search':
                # æ‰§è¡Œå¼•ç”¨æ£€ç´¢æ“ä½œ
                search_result = self._execute_reference_search(step['description'])
                if search_result:
                    # å°†æ£€ç´¢ç»“æœå­˜å‚¨ï¼Œä¾›åç»­æ­¥éª¤ä½¿ç”¨
                    if not hasattr(self, 'reference_search_results'):
                        self.reference_search_results = {}
                    # æå–æ¦‚å¿µåç§°ä½œä¸ºé”®
                    concept = self._extract_concept_from_description(step['description'])
                    self.reference_search_results[concept] = search_result
                    print(f"âœ“ å¼•ç”¨æ£€ç´¢å®Œæˆï¼Œæ¦‚å¿µ'{concept}'çš„æ‰©å±•å†…å®¹å·²å‡†å¤‡å°±ç»ª")
                else:
                    print("âŒ å¼•ç”¨æ£€ç´¢å¤±è´¥")
                    break
                    
            else:
                print(f"âŒ æœªçŸ¥çš„æ“ä½œç±»å‹: {step['action']}")
                break

    def _execute_modifications(self, locate_results, base_instruction):
        """
        æ‰§è¡Œä¿®æ”¹æ“ä½œ
        
        Args:
            locate_results: å®šä½ç»“æœ
            base_instruction: åŸºç¡€ä¿®æ”¹æŒ‡ä»¤
        """
        snippets = locate_results["snippets"]
        analysis = locate_results.get("analysis", "")
        
        print(f"   å°†åŸºäº {len(snippets)} ä¸ªå®šä½ç‰‡æ®µè¿›è¡Œä¿®æ”¹")
        if analysis:
            print(f"   åˆ†æç»“æœ: {analysis}")
        
        # å¯¹æ¯ä¸ªç‰‡æ®µé€ä¸€ä¿®æ”¹
        for i, snippet_info in enumerate(snippets):
            slide_num = snippet_info.get("slide_number", "æœªçŸ¥")
            original_code = snippet_info.get("code", "")
            description = snippet_info.get("description", "")
            
            print(f"\n   ä¿®æ”¹ç‰‡æ®µ {i+1}/{len(snippets)} (ç¬¬{slide_num}é¡µ):")
            
            # æ„å»ºåŒ…å«å®Œæ•´ä¸Šä¸‹æ–‡çš„ä¿®æ”¹æŒ‡ä»¤
            contextual_instruction = f"{base_instruction}\n\nä¸Šä¸‹æ–‡åˆ†æ: {analysis}\n\né’ˆå¯¹ç¬¬{slide_num}é¡µçš„å…·ä½“ä¿®æ”¹: {description}"
            
            modified_snippet = self.generate_modified_code(original_code, contextual_instruction, self.document_content)
            if not modified_snippet:
                print(f"   âŒ ç¬¬{slide_num}é¡µä¿®æ”¹å¤±è´¥ï¼Œè·³è¿‡")
                continue
                
            if self.show_diff_and_get_confirmation(original_code, modified_snippet):
                print(f"\n   --- æ­£åœ¨ä¿®æ”¹ç¬¬{slide_num}é¡µ ---")
                success, _ = self._find_and_replace_frame(original_code, modified_snippet)
                if success:
                    print(f"   âœ… ç¬¬{slide_num}é¡µä¿®æ”¹æˆåŠŸ")
                else:
                    print(f"   âŒ ç¬¬{slide_num}é¡µä¿®æ”¹å¤±è´¥")
            else:
                print(f"   âœ— ç¬¬{slide_num}é¡µä¿®æ”¹è¢«å–æ¶ˆ")

    def _execute_insert(self, locate_results, base_instruction):
        """
        æ‰§è¡Œæ’å…¥æ“ä½œ
        
        Args:
            locate_results: å®šä½ç»“æœï¼ˆç”¨ä½œæ’å…¥å‚è€ƒç‚¹ï¼‰
            base_instruction: æ’å…¥æŒ‡ä»¤æè¿°
        """
        snippets = locate_results["snippets"]
        analysis = locate_results.get("analysis", "")
        
        print(f"   å°†åœ¨ {len(snippets)} ä¸ªå®šä½ç‰‡æ®µåè¿›è¡Œæ’å…¥")
        if analysis:
            print(f"   åˆ†æç»“æœ: {analysis}")
        
        # é€šå¸¸åªä½¿ç”¨ç¬¬ä¸€ä¸ªç‰‡æ®µä½œä¸ºæ’å…¥å‚è€ƒç‚¹
        if not snippets:
            print("   âŒ æ²¡æœ‰æ‰¾åˆ°æ’å…¥å‚è€ƒç‚¹")
            return
            
        reference_snippet = snippets[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªç‰‡æ®µä½œä¸ºå‚è€ƒ
        slide_num = reference_snippet.get("slide_number", "æœªçŸ¥")
        reference_code = reference_snippet.get("code", "")
        
        print(f"\n   åœ¨ç¬¬{slide_num}é¡µåæ’å…¥æ–°å†…å®¹")
        
        # å‡†å¤‡æ’å…¥å†…å®¹çš„ç”Ÿæˆæç¤ºè¯
        insert_prompt = create_content_insertion_prompt(
            base_instruction, analysis, slide_num, reference_code
        )
        
        # æ£€æŸ¥æ˜¯å¦æœ‰å¼•ç”¨æ£€ç´¢ç»“æœå¯ç”¨
        reference_content = None
        if hasattr(self, 'reference_search_results') and self.reference_search_results:
            # å°è¯•åŒ¹é…ç›¸å…³çš„æ¦‚å¿µ
            for concept, result in self.reference_search_results.items():
                if concept.lower() in base_instruction.lower() or any(kw in base_instruction.lower() for kw in concept.lower().split()):
                    reference_content = result
                    break
        
        if reference_content:
            print(f"   âœ¨ å°†ä½¿ç”¨å¼•ç”¨æ£€ç´¢çš„æ‰©å±•å†…å®¹: '{reference_content['concept']}'")
            insert_prompt += f"""

ğŸ¯ å¼•ç”¨æ£€ç´¢æ‰©å±•å†…å®¹ï¼ˆæ¥è‡ªä¸“ä¸šæ–‡çŒ®ï¼‰:
æ¦‚å¿µ: {reference_content['concept']}
è´¨é‡è¯„åˆ†: {reference_content['quality_score']:.2f}

æ‰©å±•å†…å®¹:
{reference_content['enhanced_content']}

å…³é”®è¦ç‚¹:
{chr(10).join(f"- {point}" for point in reference_content.get('key_points', [])[:5])}

æ¥æºæ–‡çŒ®: {len(reference_content.get('source_papers', []))} ç¯‡ä¸“ä¸šæ–‡çŒ®

è¯·ä¼˜å…ˆä½¿ç”¨ä»¥ä¸Šæ‰©å±•å†…å®¹æ¥ç”Ÿæˆä¸“ä¸šã€å‡†ç¡®çš„å¹»ç¯ç‰‡ã€‚
"""
        
        if self.source_content:
            insert_prompt += f"\n\nåŸå§‹PDFå†…å®¹ï¼ˆç”¨äºå‚è€ƒï¼‰:\n```json\n{json.dumps(self.source_content, ensure_ascii=False, indent=2)}\n```"
        
        response = self._call_llm([{"role": "user", "content": insert_prompt}], 
                                 LATEX_EXPERT_SYSTEM_PROMPT, 
                                 json_mode=True)
        
        if not response or not response.get("insert_content"):
            print("   âŒ æ— æ³•ç”Ÿæˆæ’å…¥å†…å®¹")
            return
            
        insert_content = response["insert_content"]
        
        # æ˜¾ç¤ºè¦æ’å…¥çš„å†…å®¹é¢„è§ˆ
        print(f"\n--- è¦æ’å…¥çš„å†…å®¹é¢„è§ˆ ---")
        preview = insert_content[:300] + "..." if len(insert_content) > 300 else insert_content
        print(preview)
        print("--- é¢„è§ˆç»“æŸ ---")
        
        # è¯·æ±‚ç”¨æˆ·ç¡®è®¤
        confirm = input(f"\n{USER_CONFIRMATION_PROMPTS['insert_confirmation']}").strip().lower()
        if confirm not in ['', 'y', 'yes']:
            print("   âœ— Insert operation cancelled")
            return
        
        # æ‰§è¡Œæ’å…¥ï¼šåœ¨å‚è€ƒä»£ç ç‰‡æ®µä¹‹åæ’å…¥æ–°å†…å®¹
        insert_position = self.document_content.find(reference_code)
        if insert_position != -1:
            # æ‰¾åˆ°å‚è€ƒç‰‡æ®µçš„ç»“æŸä½ç½®
            end_position = insert_position + len(reference_code)
            
            # æ’å…¥æ–°å†…å®¹ï¼ˆåœ¨å‚è€ƒç‰‡æ®µåæ·»åŠ æ¢è¡Œç¬¦å’Œæ–°å†…å®¹ï¼‰
            new_content = (
                self.document_content[:end_position] + 
                "\n\n" + insert_content + 
                self.document_content[end_position:]
            )
            
            old_length = len(self.document_content)
            self.document_content = new_content
            new_length = len(self.document_content)
            
            print(f"   âœ… æ’å…¥æˆåŠŸï¼æ–‡æ¡£é•¿åº¦å˜åŒ–: {old_length} -> {new_length} (+{new_length - old_length})")
            
            # é‡æ–°ç”Ÿæˆæ–‡æ¡£åœ°å›¾
            print("   ğŸ”„ é‡æ–°ç”Ÿæˆæ–‡æ¡£åœ°å›¾...")
            self._build_document_map()
        else:
            print("   âŒ æ— æ³•åœ¨æ–‡æ¡£ä¸­æ‰¾åˆ°æ’å…¥å‚è€ƒç‚¹")

    def _execute_delete(self, locate_results, base_instruction):
        """
        æ‰§è¡Œåˆ é™¤æ“ä½œ
        
        Args:
            locate_results: å®šä½ç»“æœï¼ˆè¦åˆ é™¤çš„å†…å®¹ï¼‰
            base_instruction: åˆ é™¤æŒ‡ä»¤æè¿°
        """
        snippets = locate_results["snippets"]
        analysis = locate_results.get("analysis", "")
        
        print(f"   å°†åˆ é™¤ {len(snippets)} ä¸ªå®šä½ç‰‡æ®µ")
        if analysis:
            print(f"   åˆ†æç»“æœ: {analysis}")
        
        if not snippets:
            print("   âŒ æ²¡æœ‰æ‰¾åˆ°è¦åˆ é™¤çš„å†…å®¹")
            return
        
        # æ˜¾ç¤ºè¦åˆ é™¤çš„å†…å®¹
        print(f"\n--- è¦åˆ é™¤çš„å†…å®¹ ---")
        for i, snippet in enumerate(snippets, 1):
            slide_num = snippet.get("slide_number", "æœªçŸ¥")
            code = snippet.get("code", "")
            desc = snippet.get("description", "")
            preview = code[:200] + "..." if len(code) > 200 else code
            print(f"{i}. ç¬¬{slide_num}é¡µ: {desc}")
            print(f"   ä»£ç é¢„è§ˆ: {preview}")
            print()
        print("--- é¢„è§ˆç»“æŸ ---")
        
        # è¯·æ±‚ç”¨æˆ·ç¡®è®¤
        confirm = input(f"\næ‚¨ç¡®è®¤è¦åˆ é™¤è¿™{len(snippets)}ä¸ªç‰‡æ®µå—ï¼Ÿ(y/n) [y]: ").strip().lower()
        if confirm not in ['', 'y', 'yes']:
            print("   âœ— åˆ é™¤æ“ä½œè¢«å–æ¶ˆ")
            return
        
        # æ‰§è¡Œåˆ é™¤ï¼šé€ä¸ªåˆ é™¤ç‰‡æ®µï¼ˆä»åå¾€å‰åˆ é™¤ï¼Œé¿å…ä½ç½®å˜åŒ–é—®é¢˜ï¼‰
        deleted_count = 0
        snippets_sorted = sorted(snippets, key=lambda x: self.document_content.find(x.get("code", "")), reverse=True)
        
        for snippet in snippets_sorted:
            code = snippet.get("code", "")
            slide_num = snippet.get("slide_number", "æœªçŸ¥")
            
            if code in self.document_content:
                old_length = len(self.document_content)
                self.document_content = self.document_content.replace(code, "", 1)  # åªåˆ é™¤ç¬¬ä¸€ä¸ªåŒ¹é…
                new_length = len(self.document_content)
                
                if new_length < old_length:
                    deleted_count += 1
                    print(f"   âœ… å·²åˆ é™¤ç¬¬{slide_num}é¡µ (å‡å°‘{old_length - new_length}å­—ç¬¦)")
                else:
                    print(f"   âš ï¸ ç¬¬{slide_num}é¡µæœªå‘ç”Ÿå˜åŒ–")
            else:
                print(f"   âŒ æ— æ³•æ‰¾åˆ°ç¬¬{slide_num}é¡µçš„ä»£ç è¿›è¡Œåˆ é™¤")
        
        if deleted_count > 0:
            print(f"   âœ… åˆ é™¤å®Œæˆï¼æˆåŠŸåˆ é™¤{deleted_count}/{len(snippets)}ä¸ªç‰‡æ®µ")
            
            # é‡æ–°ç”Ÿæˆæ–‡æ¡£åœ°å›¾
            print("   ğŸ”„ é‡æ–°ç”Ÿæˆæ–‡æ¡£åœ°å›¾...")
            self._build_document_map()
        else:
            print("   âŒ æ²¡æœ‰ä»»ä½•å†…å®¹è¢«åˆ é™¤")

    def _save_document_if_requested(self):
        """
        Ask user whether to save document
        """
        print("\n" + "="*60)
        print("ğŸ‰ All modifications completed successfully!")
        print("ğŸ“„ Ready to save changes to file...")
        save_confirm = input("\nSave changes to file? (y/n) [y]: ").strip().lower()
        if save_confirm == '' or save_confirm == 'y':
            # ç”Ÿæˆæ–°çš„æ–‡ä»¶åï¼Œé¿å…è¦†ç›–åŸæ–‡ä»¶
            base_dir = os.path.dirname(self.tex_file_path)
            base_name = os.path.splitext(os.path.basename(self.tex_file_path))[0]
            revised_path = os.path.join(base_dir, f"{base_name}_revised.tex")
            
            try:
                with open(revised_path, 'w', encoding='utf-8') as f:
                    f.write(self.document_content)
                print(f"âœ“ File saved: {revised_path}")
                
                # æ›´æ–°å½“å‰è·¯å¾„ä¸ºæ–°æ–‡ä»¶è·¯å¾„ï¼Œä¾¿äºåç»­PDFç¼–è¯‘
                self.tex_file_path = revised_path
                
                pdf_path = self._compile_to_pdf()
                if pdf_path:
                    open_pdf = input("Open PDF automatically? (y/n) [y]: ").strip().lower()
                    if open_pdf in ['y', '']:
                        try:
                            webbrowser.open(f'file://{os.path.abspath(pdf_path)}')
                        except Exception as e:
                            print(f"Cannot auto-open PDF, please open manually: {pdf_path}")
            except Exception as e:
                print(f"âŒ Error saving file: {str(e)}")
                print("Trying to save to original location...")
                try:
                    with open(self.tex_file_path, 'w', encoding='utf-8') as f:
                        f.write(self.document_content)
                    print(f"âœ“ File saved: {self.tex_file_path}")
                except Exception as e2:
                    print(f"âŒ Still cannot save: {str(e2)}")
        else:
            print("âœ— File not saved.")
    
    def modify_content(self, description):
        """
        ä¿®æ”¹å†…å®¹çš„ç®€åŒ–ç‰ˆæœ¬ - é€‚ç”¨äºç›´æ¥è°ƒç”¨
        
        Args:
            description: ä¿®æ”¹æè¿°
            
        Returns:
            tuple: (success: bool, message: str)
        """
        try:
            print(f"\nğŸ”„ å¼€å§‹ä¿®æ”¹å†…å®¹: {description}")
            
            # æ­¥éª¤1: æ™ºèƒ½å®šä½éœ€è¦ä¿®æ”¹çš„ä½ç½®
            location_result = self.locate_code_snippet(description)
            if not location_result or not location_result.get('snippets'):
                print("   âŒ æœªèƒ½å®šä½åˆ°éœ€è¦ä¿®æ”¹çš„å†…å®¹")
                return False, f"æ— æ³•å®šä½è¦ä¿®æ”¹çš„å†…å®¹: {description}"
            
            snippets = location_result['snippets']
            analysis = location_result.get('analysis', '')
            
            print(f"   âœ“ å®šä½åˆ° {len(snippets)} ä¸ªéœ€è¦ä¿®æ”¹çš„ä½ç½®")
            if analysis:
                print(f"   ğŸ“‹ åˆ†æ: {analysis}")
            
            # æ­¥éª¤2: ä¸ºæ¯ä¸ªç‰‡æ®µç”Ÿæˆä¿®æ”¹æ–¹æ¡ˆå¹¶åº”ç”¨
            success_count = 0
            failed_modifications = []
            
            for i, snippet in enumerate(snippets, 1):
                print(f"\n   å¤„ç†ç‰‡æ®µ {i}/{len(snippets)}: {snippet.get('description', 'N/A')}")
                
                # ç”Ÿæˆä¿®æ”¹åçš„ä»£ç 
                modified_code = self.generate_modified_code(
                    snippet['code'], 
                    description, 
                    self.document_content
                )
                
                if not modified_code:
                    failed_modifications.append(f"ç‰‡æ®µ{i}: æ— æ³•ç”Ÿæˆä¿®æ”¹æ–¹æ¡ˆ")
                    continue
                
                # åº”ç”¨ä¿®æ”¹
                if snippet['code'] in self.document_content:
                    # æ›¿æ¢åŸå§‹ä»£ç 
                    self.document_content = self.document_content.replace(
                        snippet['code'], 
                        modified_code, 
                        1  # åªæ›¿æ¢ç¬¬ä¸€ä¸ªåŒ¹é…é¡¹
                    )
                    success_count += 1
                    print(f"   âœ… ç‰‡æ®µ{i}ä¿®æ”¹æˆåŠŸ")
                else:
                    failed_modifications.append(f"ç‰‡æ®µ{i}: åœ¨æ–‡æ¡£ä¸­æœªæ‰¾åˆ°åŸå§‹ä»£ç ")
                    print(f"   âŒ ç‰‡æ®µ{i}: åœ¨æ–‡æ¡£ä¸­æœªæ‰¾åˆ°åŸå§‹ä»£ç ")
            
            # æ­¥éª¤3: å¤„ç†ç»“æœ
            if success_count > 0:
                # é‡æ–°ç”Ÿæˆæ–‡æ¡£åœ°å›¾ä»¥åæ˜ æ›´æ”¹
                print("\n   ğŸ”„ é‡æ–°ç”Ÿæˆæ–‡æ¡£åœ°å›¾...")
                self._build_document_map()
                
                result_msg = f"æˆåŠŸä¿®æ”¹äº† {success_count}/{len(snippets)} ä¸ªä½ç½®"
                if failed_modifications:
                    result_msg += f"ï¼Œå¤±è´¥: {'; '.join(failed_modifications)}"
                
                print(f"\nâœ… {result_msg}")
                return True, result_msg
            else:
                error_msg = f"æ‰€æœ‰ä¿®æ”¹éƒ½å¤±è´¥äº†: {'; '.join(failed_modifications)}"
                print(f"\nâŒ {error_msg}")
                return False, error_msg
            
        except Exception as e:
            error_msg = f"ä¿®æ”¹å†…å®¹æ—¶å‡ºé”™: {e}"
            print(f"\nâŒ {error_msg}")
            return False, error_msg
    
    def interactive_session(self):
        """
        å¯åŠ¨äº¤äº’å¼ç¼–è¾‘ä¼šè¯ - ç®€åŒ–ç‰ˆæœ¬
        """
        print(f"\nğŸ¯ å¯åŠ¨äº¤äº’å¼LaTeXç¼–è¾‘å™¨")
        print(f"ğŸ“„ å½“å‰æ–‡æ¡£: {os.path.basename(self.tex_file_path)}")
        print(f"ğŸ“Š æ–‡æ¡£çŠ¶æ€: {self.document_map['total_slides']}é¡µå¹»ç¯ç‰‡" if self.document_map else "æ–‡æ¡£åœ°å›¾ä¸å¯ç”¨")
        print("\nğŸ’¡ ä½¿ç”¨è¯´æ˜:")
        print("  - è¾“å…¥ä¿®æ”¹éœ€æ±‚ï¼Œå¦‚ï¼š'ä¿®æ”¹ç¬¬3é¡µçš„æ ‡é¢˜'ã€'è°ƒæ•´å›¾ç‰‡å¤§å°'")
        print("  - è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        print("  - è¾“å…¥ 'save' ä¿å­˜å½“å‰ä¿®æ”¹")
        print("  - è¾“å…¥ 'status' æŸ¥çœ‹æ–‡æ¡£çŠ¶æ€")
        print("\n" + "="*60)
        
        while True:
            try:
                user_input = input("\nğŸ”§ è¯·è¾“å…¥ä¿®æ”¹éœ€æ±‚ > ").strip()
                
                if not user_input:
                    continue
                
                # å¤„ç†ç‰¹æ®Šå‘½ä»¤
                if user_input.lower() in ['quit', 'exit', 'q']:
                    print("\nğŸ‘‹ é€€å‡ºç¼–è¾‘å™¨")
                    self._save_document_if_requested()
                    break
                
                elif user_input.lower() == 'save':
                    self._save_document_if_requested()
                    continue
                
                elif user_input.lower() == 'status':
                    self._show_document_status()
                    continue
                
                # æ‰§è¡Œä¿®æ”¹
                success, message = self.modify_content(user_input)
                
                if success:
                    print(f"âœ… {message}")
                else:
                    print(f"âŒ {message}")
                    
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¼–è¾‘å™¨")
                self._save_document_if_requested()
                break
            except Exception as e:
                print(f"âŒ å¤„ç†è¾“å…¥æ—¶å‡ºé”™: {e}")
                continue
    
    def _show_document_status(self):
        """æ˜¾ç¤ºæ–‡æ¡£çŠ¶æ€ä¿¡æ¯"""
        print("\nğŸ“Š æ–‡æ¡£çŠ¶æ€:")
        print(f"   æ–‡ä»¶: {self.tex_file_path}")
        print(f"   å¤§å°: {len(self.document_content)} å­—ç¬¦")
        
        if self.document_map:
            print(f"   å¹»ç¯ç‰‡æ•°é‡: {self.document_map['total_slides']} é¡µ")
            
            # ç»Ÿè®¡ç‰¹æ®Šå†…å®¹
            images_count = sum(1 for slide in self.document_map['slides'] if slide.get('has_image'))
            tables_count = sum(1 for slide in self.document_map['slides'] if slide.get('has_table'))
            
            if images_count > 0:
                print(f"   å«å›¾ç‰‡é¡µé¢: {images_count} é¡µ")
            if tables_count > 0:
                print(f"   å«è¡¨æ ¼é¡µé¢: {tables_count} é¡µ")
                
            # æ˜¾ç¤ºç« èŠ‚ä¿¡æ¯
            sections = set()
            for slide in self.document_map['slides']:
                if slide.get('section'):
                    sections.add(slide['section'])
            
            if sections:
                print(f"   ç« èŠ‚: {', '.join(sorted(sections))}")
        else:
            print("   âš ï¸ æ–‡æ¡£åœ°å›¾ä¸å¯ç”¨")
        
        if hasattr(self, 'source_content') and self.source_content:
            print(f"   åŸå§‹PDFå†…å®¹: å¯ç”¨")
        else:
            print(f"   åŸå§‹PDFå†…å®¹: ä¸å¯ç”¨")
        
        if hasattr(self, 'reference_agent') and self.reference_agent:
            print(f"   å¼•ç”¨æ£€ç´¢Agent: å¯ç”¨")
        else:
            print(f"   å¼•ç”¨æ£€ç´¢Agent: ä¸å¯ç”¨")

    def _execute_reference_search(self, description: str) -> dict:
        """
        æ‰§è¡Œå¼•ç”¨æ£€ç´¢æ“ä½œ
        
        Args:
            description: æ£€ç´¢æè¿°ï¼ŒåŒ…å«ç›®æ ‡æ¦‚å¿µ
            
        Returns:
            dict: æ£€ç´¢ç»“æœï¼ŒåŒ…å«æ‰©å±•å†…å®¹
        """
        if not self.reference_agent:
            print("âŒ å¼•ç”¨æ£€ç´¢Agentæœªåˆå§‹åŒ–ï¼Œå°†ä½¿ç”¨åŸºç¡€å†…å®¹æ‰©å±•")
            return self._fallback_content_expansion(description)
        
        if not self.workflow_state:
            print("âŒ å·¥ä½œæµçŠ¶æ€ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œå¼•ç”¨æ£€ç´¢")
            return self._fallback_content_expansion(description)
        
        # ä»æè¿°ä¸­æå–æ¦‚å¿µåç§°
        concept = self._extract_concept_from_description(description)
        
        print(f"ğŸ” æ­£åœ¨æ£€ç´¢æ¦‚å¿µ: '{concept}'")
        print("   - åˆ†æåŸè®ºæ–‡å¼•ç”¨...")
        
        try:
            # å‡†å¤‡å¼•ç”¨æ£€ç´¢ä¸Šä¸‹æ–‡
            search_context = self.workflow_state.get_reference_search_context(concept)
            
            # æ·»åŠ å½“å‰å¯¹è¯ä¸Šä¸‹æ–‡
            conversation_context = "\n".join([
                f"{msg['role']}: {msg['content']}" 
                for msg in self.conversation_history[-3:]  # æœ€è¿‘3è½®å¯¹è¯
            ])
            
            # æ‰§è¡Œå¼•ç”¨æ£€ç´¢
            result = self.reference_agent.enhance_content_with_references(
                original_paper_path=search_context["original_paper_path"],
                target_concept=concept,
                context=conversation_context,
                max_references=2,  # é™åˆ¶å¼•ç”¨æ•°é‡ä»¥æé«˜æ•ˆç‡
                output_dir=search_context["output_dir"]
            )
            
            if result['success']:
                print(f"âœ… æ£€ç´¢æˆåŠŸ! è´¨é‡è¯„åˆ†: {result['content_quality_score']:.2f}")
                print(f"   æ‰¾åˆ° {len(result.get('source_papers', []))} ç¯‡ç›¸å…³æ–‡çŒ®")
                
                # ç®€åŒ–è¿”å›ç»“æœ
                return {
                    'concept': concept,
                    'enhanced_content': result['enhanced_content'],
                    'key_points': result.get('key_points', []),
                    'source_papers': result.get('source_papers', []),
                    'quality_score': result['content_quality_score']
                }
            else:
                print(f"âŒ æ£€ç´¢å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                print("âš ï¸ å°†ä½¿ç”¨åŸºç¡€å†…å®¹æ‰©å±•ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
                return self._fallback_content_expansion(description)
                
        except Exception as e:
            print(f"âŒ å¼•ç”¨æ£€ç´¢è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            print("âš ï¸ å°†ä½¿ç”¨åŸºç¡€å†…å®¹æ‰©å±•ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ")
            return self._fallback_content_expansion(description)
    
    def _extract_concept_from_description(self, description: str) -> str:
        """
        ä»æè¿°ä¸­æå–æ¦‚å¿µåç§°
        
        Args:
            description: æè¿°æ–‡æœ¬
            
        Returns:
            str: æå–çš„æ¦‚å¿µåç§°
        """
        import re
        
        # å°è¯•ä»å¼•å·ä¸­æå–
        quote_match = re.search(r"['\"](.*?)['\"]", description)
        if quote_match:
            return quote_match.group(1).strip()
        
        # å°è¯•ä»"å…³äºX"æ¨¡å¼ä¸­æå–
        about_match = re.search(r"å…³äº['\"]?(.*?)['\"]?çš„", description)
        if about_match:
            return about_match.group(1).strip()
        
        # å°è¯•ä»å¸¸è§æŠ€æœ¯è¯æ±‡ä¸­åŒ¹é…
        tech_terms = ['attention', 'transformer', 'neural', 'learning', 'model', 'network', 'algorithm']
        for term in tech_terms:
            if term in description.lower():
                # æå–åŒ…å«è¯¥è¯æ±‡çš„çŸ­è¯­
                words = description.split()
                for i, word in enumerate(words):
                    if term in word.lower():
                        # å–å‰åå„ä¸€ä¸ªè¯ä½œä¸ºæ¦‚å¿µ
                        start = max(0, i-1)
                        end = min(len(words), i+2)
                        return ' '.join(words[start:end]).strip()
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›æè¿°çš„å…³é”®è¯
        words = description.split()
        # è¿‡æ»¤æ‰å¸¸è§çš„åŠ¨è¯å’Œä»‹è¯
        stop_words = ['è·å–', 'æ£€ç´¢', 'é€šè¿‡', 'å…³äº', 'çš„', 'è¿›è¡Œ', 'ä½¿ç”¨', 'å®ç°']
        key_words = [w for w in words if w not in stop_words and len(w) > 1]
        
        if key_words:
            return ' '.join(key_words[:2])  # å–å‰ä¸¤ä¸ªå…³é”®è¯
        
        return "unknown_concept"
    
    def _fallback_content_expansion(self, description: str) -> dict:
        """
        åŸºç¡€å†…å®¹æ‰©å±•æ–¹æ¡ˆï¼ˆå½“å¼•ç”¨æ£€ç´¢å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        
        Args:
            description: æ‰©å±•æè¿°
            
        Returns:
            dict: åŸºç¡€æ‰©å±•å†…å®¹
        """
        concept = self._extract_concept_from_description(description)
        print(f"ğŸ”„ ä½¿ç”¨åŸºç¡€å†…å®¹æ‰©å±•ç”Ÿæˆ'{concept}'çš„è§£é‡Š")
        
        try:
            # å¦‚æœæœ‰åŸå§‹PDFå†…å®¹ï¼Œä»ä¸­æå–ç›¸å…³ä¿¡æ¯
            if hasattr(self, 'source_content') and self.source_content:
                relevant_content = self._extract_relevant_content_from_source(concept, self.source_content)
            else:
                relevant_content = ""
            
            # ç”ŸæˆåŸºç¡€æ‰©å±•å†…å®¹
            expanded_content = self._generate_basic_explanation(concept, relevant_content)
            
            return {
                'concept': concept,
                'enhanced_content': expanded_content,
                'key_points': self._extract_basic_key_points(expanded_content),
                'source_papers': [{'title': 'Original Paper', 'authors': ['Original Authors']}],
                'quality_score': 0.6,  # åŸºç¡€æ‰©å±•è´¨é‡åˆ†
                'method': 'fallback_expansion'
            }
            
        except Exception as e:
            print(f"âš ï¸ åŸºç¡€å†…å®¹æ‰©å±•ä¹Ÿå¤±è´¥äº†: {e}")
            return {
                'concept': concept,
                'enhanced_content': f"{concept}æ˜¯ä¸€ä¸ªé‡è¦çš„æŠ€æœ¯æ¦‚å¿µï¼Œåœ¨æœ¬ç ”ç©¶ä¸­èµ·åˆ°å…³é”®ä½œç”¨ã€‚",
                'key_points': [f"{concept}çš„é‡è¦æ€§", "åœ¨ç ”ç©¶ä¸­çš„åº”ç”¨"],
                'source_papers': [],
                'quality_score': 0.3,
                'method': 'minimal_fallback'
            }
    
    def _extract_relevant_content_from_source(self, concept: str, source_content: str) -> str:
        """ä»åŸå§‹å†…å®¹ä¸­æå–ç›¸å…³æ®µè½"""
        if not source_content or not concept:
            return ""
        
        # å°†conceptè½¬æ¢ä¸ºæœç´¢å…³é”®è¯
        search_terms = [concept.lower()]
        if ' ' in concept:
            search_terms.extend(concept.lower().split())
        
        # åˆ†æ®µæœç´¢
        paragraphs = source_content.split('\n\n')
        relevant_paragraphs = []
        
        for para in paragraphs:
            para_lower = para.lower()
            if any(term in para_lower for term in search_terms) and len(para.strip()) > 50:
                relevant_paragraphs.append(para.strip())
        
        return '\n\n'.join(relevant_paragraphs[:3])  # æœ€å¤š3ä¸ªç›¸å…³æ®µè½
    
    def _generate_basic_explanation(self, concept: str, relevant_content: str) -> str:
        """ç”ŸæˆåŸºç¡€æŠ€æœ¯è§£é‡Š"""
        if relevant_content:
            return f"""## {concept.title()}

**æŠ€æœ¯æ¦‚è¿°:**
{concept}æ˜¯æœ¬ç ”ç©¶ä¸­é‡‡ç”¨çš„é‡è¦æŠ€æœ¯æ–¹æ³•ã€‚

**åœ¨æœ¬ç ”ç©¶ä¸­çš„åº”ç”¨:**
{relevant_content[:500]}...

**æŠ€æœ¯ç‰¹ç‚¹:**
â€¢ åœ¨ç›¸å…³é¢†åŸŸå…·æœ‰é‡è¦æ„ä¹‰
â€¢ èƒ½å¤Ÿæœ‰æ•ˆè§£å†³ç‰¹å®šé—®é¢˜
â€¢ å…·æœ‰è‰¯å¥½çš„æ€§èƒ½è¡¨ç°

**ç›¸å…³èƒŒæ™¯:**
è¯¥æŠ€æœ¯åœ¨å½“å‰ç ”ç©¶é¢†åŸŸå¾—åˆ°å¹¿æ³›åº”ç”¨ï¼Œä¸ºé—®é¢˜è§£å†³æä¾›äº†æœ‰æ•ˆé€”å¾„ã€‚
"""
        else:
            return f"""## {concept.title()}

**å®šä¹‰:**
{concept}æ˜¯æœ¬ç ”ç©¶ä¸­çš„å…³é”®æŠ€æœ¯æ¦‚å¿µã€‚

**é‡è¦æ€§:**
â€¢ åœ¨ç ”ç©¶æ–¹æ³•ä¸­èµ·åˆ°æ ¸å¿ƒä½œç”¨
â€¢ ä¸ºé—®é¢˜è§£å†³æä¾›æŠ€æœ¯æ”¯æ’‘
â€¢ å…·æœ‰ç†è®ºå’Œå®è·µæ„ä¹‰

**åº”ç”¨ç‰¹ç‚¹:**
è¯¥æŠ€æœ¯æ–¹æ³•åœ¨ç›¸å…³ç ”ç©¶ä¸­å±•ç°å‡ºè‰¯å¥½çš„æ€§èƒ½ï¼Œä¸ºç ”ç©¶ç›®æ ‡çš„å®ç°æä¾›äº†é‡è¦ä¿éšœã€‚
"""
    
    def _extract_basic_key_points(self, content: str) -> list:
        """ä»åŸºç¡€å†…å®¹ä¸­æå–å…³é”®ç‚¹"""
        key_points = []
        lines = content.split('\n')
        
        for line in lines:
            line = line.strip()
            if line.startswith('â€¢ ') or line.startswith('- '):
                key_points.append(line[2:])
            elif line.startswith('**') and line.endswith(':**'):
                key_points.append(line.strip('*:'))
        
        return key_points[:5]  # æœ€å¤š5ä¸ªå…³é”®ç‚¹
